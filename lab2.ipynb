{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d98a4e-9418-4397-8b7a-8088621543bc",
   "metadata": {},
   "source": [
    "# Lista 2\n",
    "\n",
    "## Uczenie maszynowe i sztuczna inteligencja\n",
    "\n",
    "* [Naiwny klasyfikator bayesowski](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) oraz [Naiwny wielomianowy klasyfikator bayesowski](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes)\n",
    "* [Tokenizacja](https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization)\n",
    "* [Multizbiór słów](https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
    "* [N-gram](https://en.wikipedia.org/wiki/N-gram), [Bigram](https://en.wikipedia.org/wiki/Bigram), [Trigram](https://en.wikipedia.org/wiki/Trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd6799-47e0-46c6-b8e3-64a0cb60587c",
   "metadata": {},
   "source": [
    "## Wprowadzenie \n",
    "\n",
    "Spamowanie jest jednym z najprostszych ataków w przesyłaniu wiadomości e-mail. Użytkownicy często otrzymują irytujące wiadomości spamowe oraz złośliwe wiadomości phishingowe, subskrybując różne strony internetowe, produkty, usługi, katalogi, biuletyny informacyjne oraz inne rodzaje komunikacji elektronicznej. W niektórych przypadkach, spamowe wiadomości e-mail są generowane przez wirusy lub konie trojańskie rozsyłane masowo.\n",
    "\n",
    "Istnieje wiele rozwiązań do filtrowania spamu, takich jak techniki filtrowania na czarnej i białej liście, podejścia oparte na drzewach decyzyjnych, podejścia oparte na adresach e-mail oraz metody oparte na uczeniu maszynowym. Większość z nich opiera się głównie na analizie tekstu zawartości e-maila. W rezultacie rośnie zapotrzebowanie na skuteczne filtry antyspamowe, które automatycznie identyfikują i usuwają wiadomości spamowe lub ostrzegają użytkowników przed możliwymi wiadomościami spamowymi. Jednak spamerzy zawsze badają luki istniejących technik filtrowania spamu i wprowadzają nowy projekt do rozprzestrzeniania spamu w szerokim zakresie np. atak tokenizacji czasami wprowadza w błąd filtry antyspamowe, dodając dodatkowe spacje. Dlatego też treści e-maili muszą być strukturalizowane. Ponadto, pomimo posiadania najwyższej dokładności w wykrywaniu spamu za pomocą uczenia maszynowego, fałszywe pozytywy (False Positive, FP) stanowią problem z powodu jednorazowego wykrywania zagrożeń e-mailowych. Aby zaradzić problemom z fałszywymi pozytywami oraz zmianom w różnych projektach ataków, z tekstu usuwane są słowa kluczowe oraz inne niepożądane informacje przed dalszą analizą. Po wstępnym przetwarzaniu, te teksty przechodzą przez liczne metody ekstrakcji cech, takie jak word2vec, word n-gram, character n-gram oraz kombinacje n-gramów o zmiennych długościach. Różne techniki uczenia maszynowego, takie jak support vector machine (SVM), decision tree (DT), logistic regression (LR) oraz multinomial naıve bayes (MNB), są stosowany aby dokonać klasyfikacji e-maili.\n",
    "\n",
    "Na tej liste skoncentrujemy się tylko na metodzie naiwnego klasyfikatora bayesowskiego przedstawionego na wykładzie wraz z wersją [wielomianową](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes).\n",
    "\n",
    "#### **Uwaga**\n",
    "\n",
    "**Wszystkie implementacje klasyfikatorów należy napisać samemu. Na tej liście nie korzystamy z implementacji klasyfikatorów istniejących w popularnych bibliotekach.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550496e-1cac-4071-935a-6f92eec8afd7",
   "metadata": {},
   "source": [
    "\n",
    "# Klasyfikatory Naiwnego Bayesa (NB)\n",
    "\n",
    "W naszych eksperymentach po wstępnym przetworzeniu każda wiadomość jest ostatecznie reprezentowana jako wektor $\\mathbf{x}=(x_1, \\ldots , x_m)$, gdzie $x_1, \\ldots , x_m$ są wartościami atrybutów $X_1, \\ldots , X_m$ , a każdy atrybut dostarcza informacje o określonym tokenie wiadomości. W najprostszym przypadku wszystkie atrybuty są wartościami boolowskimi: $X_i = 1$, jeśli wiadomość zawiera dany token; w przeciwnym razie, $X_i = 0$. Alternatywnie, ich wartości mogą być częstotliwościami tokenów (TF), pokazującymi, ile razy odpowiadający token występuje w wiadomości. Atrybuty z wartościami TF przenoszą więcej informacji niż atrybuty boolowskie.\n",
    "\n",
    "Z twierdzenia Bayesa wynika, że prawdopodobieństwo, że wiadomość o wektorze $\\mathbf{x} = (x_1, \\ldots, x_m)$ należy do kategorii $c$, wynosi: \n",
    "\n",
    "$$\n",
    "p(c | \\mathbf{x}) = \\frac{p(c) \\cdot p(\\mathbf{x} | c)}{p(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "Ponieważ mianownik nie zależy od kategorii, klasyfikator NB klasyfikuje każdą wiadomość do kategorii, która maksymalizuje $p(c) \\cdot p(\\mathbf{x} | c)$. W przypadku filtrowania spamu oznacza to klasyfikowanie wiadomości jako spamu, gdy: \n",
    "\n",
    "$$\n",
    "\\frac{p(c_s) \\cdot p(\\mathbf{x} | c_s)}{p(c_s) \\cdot p(\\mathbf{x} | c_s) + p(c_h) \\cdot p(\\mathbf{x} | c_h)} > T\n",
    "$$\n",
    "\n",
    "gdzie $T = 0.5$, a $c_h$ i $c_s$ oznaczają kategorie ham i spam. Zmieniając $T$, można zdecydować się na więcej prawdziwych negatywów (poprawnie sklasyfikowane wiadomości ham) kosztem mniej prawdziwych pozytywów (poprawnie sklasyfikowane wiadomości spam), lub odwrotnie. Prawdopodobieństwa a priori $p(c)$ są zwykle szacowane przez podzielenie liczby treningowych wiadomości kategorii $c$ przez łączną liczbę treningowych wiadomości. Prawdopodobieństwa $p(\\mathbf{x} | c)$ są szacowane w różny sposób w każdej wersji NB - patrz wykład.\n",
    "\n",
    "# Naiwny klasyfikator bayesowski wielomianowy (MNB)\n",
    "\n",
    "Klasyfikator [wielomianowy](https://en.wikipedia.org/wiki/Multinomial_distribution) bayesowski z atrybutami TF traktuje każdą wiadomość $d$ jako [multizbiór]((https://en.wikipedia.org/wiki/Bag-of-words_model)) tokenów, zawierający każdy token $t_i$ tyle razy, ile występuje w $d$. Dlatego $d$ można przedstawić jako $\\mathbf{x} = (x_1, ..., x_m)$, gdzie każde $x_i$ to teraz liczba wystąpień $t_i$ w $d$. Ponadto, każda wiadomość $d$ z kategorii $c$ jest postrzegana jako wynik niezależnego wyboru $|d|$ tokenów z $F=\\{t_1,\\ldots,t_m\\}$ z powtórzeniami, z prawdopodobieństwem $p(t_i | c)$ dla każdego $t_i$. Wówczas $p(\\mathbf{x} | c)$ jest rozkładem wielomianowym:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid c) = p(|d|) \\cdot |d|! \\cdot \\prod_{i=1}^{d} \\frac{p(t_i \\mid c)^{x_i}}{x_i !}\n",
    "$$\n",
    "\n",
    "gdzie zakładamy, że $|d|$ nie zależy od kategorii $c$. Jest to dodatkowe uproszczające założenie, które jest bardziej dyskusyjne w filtrowaniu spamu. Na przykład, prawdopodobieństwo otrzymania bardzo długiej wiadomości spamowej wydaje się mniejsze niż prawdopodobieństwo otrzymania równie długiej wiadomości ham. Kryterium klasyfikacji wiadomości jako spamu staje się:\n",
    "\n",
    "$$\n",
    "\\frac{p(c_s) \\cdot \\prod_{i=1}^{m} p(t_i \\mid c_s)^{x_i}}{p(c_s)\\cdot\\prod_{i=1}^{m} p(t_i \\mid c_s)^{x_i} + p(c_h)\\cdot\\prod_{i=1}^{m} p(t_i \\mid c_h)^{x_i}}  > T\n",
    "$$\n",
    "\n",
    "gdzie każde $p(t_i | c)$ jest szacowane jako:\n",
    "\n",
    "$$\n",
    "p(t \\mid c) = \\frac{\\alpha + N_{t,c}}{\\alpha \\cdot m + N_c}\n",
    "$$\n",
    "gdzie $N_{t,c}$ to liczba wystąpień tokena $t$ w treningowych wiadomościach kategorii $c$, podczas gdy $N_c = \\sum_{i=1}^{m} N_{t_i,c}$ to łączna liczba wiadomości treningowych kategorii $c$. W praktyce dodaje się jeszcze parametr $\\alpha$ który reprezentuje wygładzenie (smoothing) i rozwiązuje problem zerowego prawdopodobieństwa, patrz [http://www.paulgraham.com/spam.html](http://www.paulgraham.com/spam.html) (np. $\\alpha=1$).\n",
    "\n",
    "\n",
    "### Przykładowe dane wielomianowe\n",
    "\n",
    "Zatem każda wiadomość $d$  składa się z różnych tokenów $t_i$, a każde z tych $t_i$ należy do słownika $\\mathcal{V}$. Jeśli $\\mathcal{V}$ zawiera np. $8$ tokenów, $t_1,t_2,...,t_8$, a wiadomość to: $t_1 t_2 t_2 t_6 t_3 t_2 t_8$, reprezentacja tej wiadomości będzie następująca:\n",
    "\n",
    "| |$t_1$|$t_2$|$t_3$|$t_4$|$t_5$|$t_6$|$t_7$|$t_8$|\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "|$\\mathbf{x}$| 1|3 |1 | 0| 0|1 | 0|1 |\n",
    "\n",
    "Po dodaniu kilku innych losowych wiadomości, zbiór danych wygląda tak:\n",
    "\n",
    "|$t_1$|$t_2$|$t_3$|$t_4$|$t_5$|$t_6$|$t_7$|$t_8$|$c$|\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| 1|3 |1 | 0| 0|1 | 0|1 | spam|\n",
    "| 1|0 |0 | 0| 1|1 | 1|3 | ham|\n",
    "| 0|0 |0 | 0| 0|2 | 1|2 | spam|\n",
    "\n",
    "Przyjmując klasy ($1$-spam,$0$-ham) mamy $c = [1,0,1]$. Teraz, porównując z równaniem powyżej,\n",
    "\n",
    "- $N_{t_i,c}$ to liczba wystąpień cechy $t_i$ w każdej unikalnej klasie $c$. Na przykład, dla $c=1$, $N_{t_1,c}=1, N_{t_6,c}=3$\n",
    "- $N_c$ to całkowita liczba wystąpień wszystkich cech w każdej unikalnej klasie $c$. Na przykład, dla $c=1$, $N_c=12$\n",
    "- $m=8$ to całkowita liczba cech\n",
    "- $\\alpha=1$ jest znany jako parametr wygładzania. Jest on potrzebny do problemu zerowego prawdopodobieństwa (patrz [http://www.paulgraham.com/spam.html](http://www.paulgraham.com/spam.html))\n",
    "\n",
    "# Niedomiar zmiennoprzecinkowy (floating point underflow)\n",
    "\n",
    "Aby uniknąć problemu niedomiaru zmiennoprzecinkowego, mnożenie zbioru małych prawdopodobieństw, czyli po prostu iloczyn stanie się zbyt mały, aby go reprezentować i zostanie zastąpiony przez 0. Zamiast obliczać\n",
    "$$\n",
    "P(c) \\prod_{i=1}^m P(t_i | c)\n",
    "$$\n",
    "co może spowodować niedomiar, rozważmy obliczenie logarytmu tego wyrażenia,\n",
    "$$\n",
    "\\log\\left(P(c) \\prod_{i=1}^m P(t_i | c)\\right)\n",
    "$$\n",
    "co równoważnie można zapisać jako\n",
    "$$\n",
    "\\log(P(c))+ \\sum_{i=1}^m \\log(P(t_i | c))\n",
    "$$\n",
    "Następnie zauważ, że jeśli\n",
    "$$\n",
    "\\log(P(c_s))+ \\sum_{i=1}^m \\log(P(t_i | c_s)) > \\log(P(c_h))+ \\sum_{i=1}^m \\log(P(t_i | c_h))\n",
    "$$\n",
    "wtedy, ponieważ $\\log(x) > \\log(y)$ iff $x > y$, to\n",
    "$$\n",
    "P(c_s) \\prod_{i=1}^m P(t_i | c_s) > P(c_h) \\prod_{i=1}^m P(t_i | c_h)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff1e5a-8599-412a-9494-45699a65a2fb",
   "metadata": {},
   "source": [
    "## Zadanie 1 (10pt)\n",
    "\n",
    "### Klasyfikator oparty na algorytmie NB\n",
    "\n",
    "#### Cel:\n",
    "Zbudować prosty klasyfikator spamu oparty na NB, który będzie w stanie wykryć i odfiltrować niechciane wiadomości e-mail.\n",
    "\n",
    "#### Opis:\n",
    "1. Zbierz zbiór danych zawierający etykiety (spam/nie-spam) oraz treść wiadomości e-mail np. [Enron-Spam](http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/index.html) lub [SMS Spam Collection](https://archive.ics.uci.edu/dataset/228/sms+spam+collection) lub [E-mail Spam](https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv) lub ...\n",
    "2. Przygotuj dane poprzez tokenizację słów i usuń zbędne znaki interpunkcyjne.\n",
    "3. Zaimplementuj NB, który będzie w stanie klasyfikować wiadomości jako spam lub nie-spam na podstawie występujących słów.\n",
    "4. Podziel dane na zbiór treningowy i testowy (np. 70% do treningu, 30% do testu).\n",
    "5. Wytrenuj klasyfikator NB na danych treningowych.\n",
    "6. Przetestuj klasyfikator na danych testowych i oceniaj jego skuteczność przy użyciu metryk: [precision i recall](https://en.wikipedia.org/wiki/Precision_and_recall), [f1-score](https://en.wikipedia.org/wiki/F-score) oraz [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision).\n",
    "7. Dokonaj analizy wyników i przedstaw wnioski.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db03424-f98e-4b03-8cb3-cbb1cb5d4935",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T20:39:13.398624Z",
     "start_time": "2024-03-29T20:39:11.927677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correct Ham Percentage:      94.0\n",
      "Correct Spam Percentage:     81.0\n",
      "Correct Overall Percentage:  87.5\n",
      "\n",
      "Ham Incorrectly Labelled as Spam:\n",
      "\t2151.2000-09-05.farmer.ham.txt\n",
      "\t3933.2001-03-22.farmer.ham.txt\n",
      "\t4731.2001-07-09.farmer.ham.txt\n",
      "\t5095.2001-12-02.farmer.ham.txt\n",
      "\t5067.2001-11-13.farmer.ham.txt\n",
      "\t0637.2000-03-20.farmer.ham.txt\n",
      "\n",
      "Spam Incorrectly Labelled as Ham:\n",
      "\t1489.2004-07-03.GP.spam.txt\n",
      "\t2111.2004-09-10.GP.spam.txt\n",
      "\t1717.2004-07-27.GP.spam.txt\n",
      "\t3110.2004-12-08.GP.spam.txt\n",
      "\t2803.2004-11-12.GP.spam.txt\n",
      "\t2827.2004-11-16.GP.spam.txt\n",
      "\t0130.2004-01-01.GP.spam.txt\n",
      "\t0567.2004-02-24.GP.spam.txt\n",
      "\t2110.2004-09-10.GP.spam.txt\n",
      "\t4787.2005-06-29.GP.spam.txt\n",
      "\t2953.2004-11-26.GP.spam.txt\n",
      "\t0032.2003-12-19.GP.spam.txt\n",
      "\t2287.2004-09-26.GP.spam.txt\n",
      "\t2348.2004-10-02.GP.spam.txt\n",
      "\t0838.2004-04-13.GP.spam.txt\n",
      "\t3614.2005-01-29.GP.spam.txt\n",
      "\t4270.2005-04-16.GP.spam.txt\n",
      "\t1196.2004-05-24.GP.spam.txt\n",
      "\t3963.2005-03-03.GP.spam.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": "<function print(*args, sep=' ', end='\\n', file=None, flush=False)>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "# tokenization\n",
    "def words(filename):\n",
    "    # Get list of lines\n",
    "    infile = open(filename, 'rb')\n",
    "    lines = infile.readlines()\n",
    "    infile.close()\n",
    "\n",
    "    # For each line, delimit word by space \n",
    "    # and add to list of words. Also, convert\n",
    "    # all words to lowercase for convenience\n",
    "    return [word.strip().decode('utf-8', 'ignore').lower() for line in lines for word in line.split()]\n",
    "\n",
    "\n",
    "# makes a distribution of words based on a training set\n",
    "def lexicon(k):\n",
    "    # Extract training directories\n",
    "    spam_training_directory = '/Users/wiktoriapazdzierniak/Documents/Studia /8_SEM/UMSI/umsi/Lista2/spamtraining'\n",
    "\n",
    "    ham_training_directory = '/Users/wiktoriapazdzierniak/Documents/Studia /8_SEM/UMSI/umsi/Lista2/hamtraining'\n",
    "\n",
    "    # Create spam distribution\n",
    "    spam_distribution = {}\n",
    "    files = os.listdir(spam_training_directory)\n",
    "    for file in files:\n",
    "        list_of_words = words(spam_training_directory + '/' + file)\n",
    "        for word in list_of_words:\n",
    "            if word in spam_distribution:\n",
    "                spam_distribution[word] += 1\n",
    "            else:\n",
    "                spam_distribution[word] = 1\n",
    "\n",
    "    # Create ham distribution\n",
    "    ham_distribution = {}\n",
    "    files = os.listdir(ham_training_directory)\n",
    "    for file in files:\n",
    "        list_of_words = words(ham_training_directory + '/' + file)\n",
    "        for word in list_of_words:\n",
    "            if word in ham_distribution:\n",
    "                ham_distribution[word] += 1\n",
    "            else:\n",
    "                ham_distribution[word] = 1\n",
    "\n",
    "    # Remove all key,value pairs that\n",
    "    # have a value less than k; warning, we have to use the copy of spam and ham distribution to \n",
    "    # delete element at given key\n",
    "\n",
    "    spamkeys = spam_distribution.copy().keys()\n",
    "    hamkeys = ham_distribution.copy().keys()\n",
    "\n",
    "    for key in spamkeys:\n",
    "        if spam_distribution[key] < k:\n",
    "            del spam_distribution[key]\n",
    "\n",
    "    for key in hamkeys:\n",
    "        if ham_distribution[key] < k:\n",
    "            del ham_distribution[key]\n",
    "\n",
    "    return ham_distribution, spam_distribution\n",
    "\n",
    "\n",
    "def probability(word, category, ham_distribution, spam_distribution, m):\n",
    "    # Compute P(w = word | category), smoothing the result\n",
    "    # with Laplacian Smoothing with parameter m\n",
    "\n",
    "    distribution = ham_distribution if category == 'ham' else spam_distribution\n",
    "\n",
    "    V = len(distribution)\n",
    "\n",
    "    keys = distribution.keys()\n",
    "\n",
    "    numerator = (distribution[word] + m if word in keys else m)  # number of occurrences of the word + m\n",
    "    denominator = sum([distribution[key] for key in\n",
    "                       keys]) + m * V  # number of all word occurrences in the distribution + m*dictionary length\n",
    "\n",
    "    return numerator / float(denominator)\n",
    "\n",
    "\n",
    "def classify_email(email, ham_distribution, spam_distribution, m):\n",
    "    email_words = words(email)\n",
    "\n",
    "    ham_probability = 0\n",
    "    spam_probability = 0\n",
    "\n",
    "    for word in email_words:\n",
    "        ham_probability += math.log(probability(word, 'ham', ham_distribution, spam_distribution, m))\n",
    "        spam_probability += math.log(probability(word, 'spam', ham_distribution, spam_distribution, m))\n",
    "\n",
    "    return 'ham' if ham_probability > spam_probability else 'spam'\n",
    "\n",
    "\n",
    "def test_filter(hamtesting, spamtesting, k, m):\n",
    "    ham_distribution, spam_distribution = lexicon(k)  # make a dictionaries based on a TRAINING sets\n",
    "\n",
    "    # files that have benn classified incorrectly\n",
    "    spam_as_ham = []\n",
    "    ham_as_spam = []\n",
    "\n",
    "    ham_hit = 0\n",
    "    ham_total = 0\n",
    "    ham_testing_files = os.listdir(hamtesting)\n",
    "    for file in ham_testing_files:\n",
    "        if classify_email(hamtesting + '/' + file, ham_distribution, spam_distribution, m) == 'ham':\n",
    "            ham_hit += 1\n",
    "        else:\n",
    "            ham_as_spam.append(file)\n",
    "        ham_total += 1\n",
    "\n",
    "    spam_hit = 0\n",
    "    spam_total = 0\n",
    "    spam_testing_files = os.listdir(spamtesting)\n",
    "    for file in spam_testing_files:\n",
    "        if classify_email(spamtesting + '/' + file, ham_distribution, spam_distribution, m) == 'spam':\n",
    "            spam_hit += 1\n",
    "        else:\n",
    "            spam_as_ham.append(file)\n",
    "        spam_total += 1\n",
    "\n",
    "    ham_hit_ratio = ham_hit / float(ham_total)\n",
    "    spam_hit_ratio = spam_hit / float(spam_total)\n",
    "\n",
    "    return ham_hit_ratio, spam_hit_ratio, ham_total, spam_total, ham_as_spam, spam_as_ham\n",
    "\n",
    "\n",
    "# ---------- CODE STARTS HERE ----------\n",
    "\n",
    "spamtesting = '/Users/wiktoriapazdzierniak/Documents/Studia /8_SEM/UMSI/umsi/Lista2/spamtesting'\n",
    "hamtesting = '/Users/wiktoriapazdzierniak/Documents/Studia /8_SEM/UMSI/umsi/Lista2/hamtesting'\n",
    "\n",
    "ham_hit_ratio, spam_hit_ratio, ham_total, spam_total, ham_as_spam, spam_as_ham = test_filter(hamtesting, spamtesting,\n",
    "                                                                                             k=5, m=1)\n",
    "\n",
    "print()\n",
    "print(\"Correct Ham Percentage:     \", ham_hit_ratio * 100)\n",
    "print(\"Correct Spam Percentage:    \", spam_hit_ratio * 100)\n",
    "print(\"Correct Overall Percentage: \",\n",
    "      (ham_hit_ratio * ham_total + spam_hit_ratio * spam_total) / (ham_total + spam_total) * 100)\n",
    "\n",
    "print(\"\\nHam Incorrectly Labelled as Spam:\")\n",
    "for file in ham_as_spam:\n",
    "    print(\"\\t\" + file)\n",
    "\n",
    "print(\"\\nSpam Incorrectly Labelled as Ham:\")\n",
    "for file in spam_as_ham:\n",
    "    print(\"\\t\" + file)\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a933bb-c803-4e52-a562-e2a47944fb5f",
   "metadata": {},
   "source": [
    "## Zadanie 2 (15pt)\n",
    "\n",
    "### Klasyfikator oparty na n-gramach MNB\n",
    "\n",
    "#### Cel:\n",
    "Zbudować klasyfikator spamu, wykorzystując n-gramy w połączeniu MNB, aby poprawić skuteczność klasyficji wiadomości e-mail.\n",
    "\n",
    "#### Opis:\n",
    "1. Zbierz zbiór danych zawierający etykiety (spam/nie-spam) oraz treść wiadomości e-mail np. [Enron-Spam](http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/index.html) lub [SMS Spam Collection](https://archive.ics.uci.edu/dataset/228/sms+spam+collection) lub [E-mail Spam](https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv) lub ...\n",
    "2. Przygotuj dane poprzez tworzenie n-gramów z treści wiadomości e-mail tzn. unigramy, bigramy, trigramy.\n",
    "3. Zaimplementuj MNB, który będzie w stanie klasyfikować wiadomości jako spam lub nie-spam, wykorzystując n-gramy jako cechy.\n",
    "4. Podziel dane na zbiór treningowy i testowy (np. 70% do treningu, 30% do testu).\n",
    "5. Wytrenuj klasyfikator MNB na danych treningowych, wykorzystując n-gramy jako cechy.\n",
    "6. Przetestuj klasyfikator na danych testowych i oceniaj jego skuteczność przy użyciu metryk: [precision i recall](https://en.wikipedia.org/wiki/Precision_and_recall), [f1-score](https://en.wikipedia.org/wiki/F-score) oraz [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision).\n",
    "7. Dokonaj analizy wyników i porównaj je z wynikami klasyfikatora opartego na słowach.\n",
    "8. Przedstaw wnioski dotyczące skuteczności klasyfikatora opartego na n-gramach oraz wpływu różnych typów n-gramów na skuteczność klasyfikacji.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b2135aa-3e93-4bd9-8d6d-467f14e29f3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T11:11:33.644601Z",
     "start_time": "2024-04-05T11:11:33.020814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  label                                               text\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Wczytywanie danych i zapisywanie ich w Data Frame\n",
    "sms_df = pd.read_csv('umsi/Lista2/sms+spam+collection/SMSSpamCollection', delimiter='\\t', names=['label', 'text'])\n",
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['00 in our', '00 sub 16', '00 subs 16', ..., 'zouk with nichols',\n       'zyada kisi ko', 'ú1 20 poboxox36504w45wq'], dtype=object)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# funkcja przeksztalca tekst zawarty w obiekcie df na macierz cech, która reprezentuje liczbę wystąpień n-gramów w każdym dokumencie\n",
    "def get_n_grams(df, n):\n",
    "    model = CountVectorizer(ngram_range=(n, n))\n",
    "    X = model.fit_transform(df['text'])  # Wynikowa macierz X będzie miała kształt (liczba dokumentów,liczba n-gramow)\n",
    "    return model, X\n",
    "\n",
    "\n",
    "model, X = get_n_grams(sms_df, 3)\n",
    "#df_output = pd.DataFrame(data = X, columns = model.get_feature_names_out())\n",
    "#df_output.T.tail(5)\n",
    "model.get_feature_names_out()  # zwraca liste n-gramow (kolumny w macierzy cech)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T14:59:48.133034Z",
     "start_time": "2024-04-05T14:59:47.998029Z"
    }
   },
   "id": "c85cafe085ecde08",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes:\n",
    "    # kostruktor przyjmuje 2 parametry: dlugosc n-gramu i parametr wygladzenia ustawiony domyslnie na 1\n",
    "    def __init__(self, gram_len, alpha=1):\n",
    "        self.class_probs = {}\n",
    "        self.cond_probs = {}\n",
    "        self.n = gram_len\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def train(self, df):\n",
    "        # oblicza prawdopodobienstwo a priori i tworzy slownik z ppb dla odpowiedniej z klas(ham/spam)\n",
    "        self.class_probs = {\n",
    "            'ham': sum(df['label'] == 'ham') / len(df),\n",
    "            'spam': sum(df['label'] == 'spam') / len(df)\n",
    "        }\n",
    "\n",
    "        self.model, X = get_n_grams(df, self.n)\n",
    "        feature_names = self.model.get_feature_names_out()  # uzyskuje liste unikalnych n-gramow\n",
    "        m = len(feature_names)\n",
    "\n",
    "        # obliczamy ile razy każdy n-gram wystąpił w klasach ham i spam\n",
    "        N_c_ham = sum(X[df['label'] == 'ham'].toarray().ravel())\n",
    "        N_c_spam = sum(X[df['label'] == 'spam'].toarray().ravel())\n",
    "\n",
    "        for token in feature_names:  #przechodzimy przez liste wszystkich n-gramow\n",
    "            token_idx = np.where(feature_names == token)[0][0]  # szukamy indeksu danego n-gramu w liscie feature_names\n",
    "            # dla kazdego n-gramu obliczamy sume liczności tego n-gramu dla klas 'ham' i 'spam'.\n",
    "            N_tc_ham = X[df['label'] == 'ham', token_idx].sum()\n",
    "            N_tc_spam = X[df['label'] == 'spam', token_idx].sum()\n",
    "\n",
    "            # obliczamy warunkowe prawdopodobieństwa dla każdej klasy 'ham' i 'spam' dla danego n-gramu \n",
    "            # patrz wzor: p(t|c) = (alpha+N_t,c)/(alpha*m+N_c)\n",
    "            self.cond_probs[token] = {\n",
    "                'ham': (self.alpha + N_tc_ham) / (self.alpha * m + N_c_ham),\n",
    "                'spam': (self.alpha + N_tc_spam) / (self.alpha * m + N_c_spam)\n",
    "            }\n",
    "\n",
    "    # funkcja przewiduje czy wiadomosc jest spamem czy nie\n",
    "    def predict(self, message):\n",
    "\n",
    "        X = self.model.transform([message])\n",
    "        feature_names = self.model.get_feature_names_out()\n",
    "\n",
    "        # to avoid floating point underflow use log\n",
    "        ham_prob = np.log(self.class_probs['ham'])\n",
    "        spam_prob = np.log(self.class_probs['spam'])\n",
    "\n",
    "        # Funkcja przechodzi po wszystkich n-gramach w nowej wiadomości i dla każdego n-gramu, sprawdza już wcześniej \n",
    "        # obliczone prawdopodobieństwa warunkowe dla każdej klasy ('ham' i 'spam')\n",
    "        for token_idx in X.indices:\n",
    "            token1 = feature_names[token_idx]\n",
    "            ham_prob += np.log(self.cond_probs[token1]['ham'])\n",
    "            spam_prob += np.log(self.cond_probs[token1]['spam'])\n",
    "\n",
    "        if spam_prob > ham_prob:\n",
    "            return 'spam'\n",
    "        else:\n",
    "            return 'ham'\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T14:59:53.182383Z",
     "start_time": "2024-04-05T14:59:53.174588Z"
    }
   },
   "id": "9d492badab94267b",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def properties(nb, df):\n",
    "    # true values, then how predicted\n",
    "    values = {'ham': {'ham': 0, 'spam': 0},\n",
    "              'spam': {'ham': 0, 'spam': 0}}\n",
    "    true_vals = df['label']\n",
    "    pred_vals = df['text'].apply(nb.predict)\n",
    "    for (true_val, pred_val) in zip(true_vals, pred_vals):\n",
    "        values[true_val][pred_val] += 1\n",
    "\n",
    "    accuracy = (values['ham']['ham'] + values['spam']['spam']) / len(df)\n",
    "    precision = values['spam']['spam'] / (values['spam']['spam'] + values['ham']['spam'])\n",
    "    recall = values['spam']['spam'] / (values['spam']['spam'] + values['spam']['ham'])\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    result = {'accuracy': accuracy,\n",
    "              'precision': precision,\n",
    "              'recall': recall,\n",
    "              'f1': f1}\n",
    "    return result\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T14:45:25.411871Z",
     "start_time": "2024-04-05T14:45:25.408329Z"
    }
   },
   "id": "5af469de96a92274",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# dzielimy dane na zbior treningowy i testowy\n",
    "mask = np.random.rand(len(sms_df)) < 0.7\n",
    "train = sms_df[mask]\n",
    "test = sms_df[~mask]\n",
    "\n",
    "# trenujemy nasz model\n",
    "nb = MultinomialNaiveBayes(1)\n",
    "nb.train(train)\n",
    "result_train = properties(nb, train)\n",
    "result_test = properties(nb, test)\n",
    "#print(result_test)\n",
    "#print(result_train)\n",
    "\n",
    "result_test_df = pd.DataFrame(result_test, index=[0])\n",
    "result_train_df = pd.DataFrame(result_train, index=[0])\n",
    "combined_results_df = pd.concat([result_test_df, result_train_df], keys=['Test', 'Train'])\n",
    "\n",
    "combined_results_df.to_csv('combined_results.csv', mode='a', header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T15:06:32.088191Z",
     "start_time": "2024-04-05T15:06:19.588311Z"
    }
   },
   "id": "6fb45b3ea3f3164a",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T14:57:56.387678Z",
     "start_time": "2024-04-05T14:57:56.380736Z"
    }
   },
   "id": "6ed744be722c83c2",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "57f2ea7d37d1a586"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
